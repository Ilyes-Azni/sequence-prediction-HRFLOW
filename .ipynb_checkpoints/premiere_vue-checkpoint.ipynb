{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding sequence prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence prediction is about guessing the next step in a series. It uses what happened before. It is key in making guesses right in many areas like guessing what you want to see on the web, what you might buy next, or what the weather will be.\n",
    "\n",
    "There are several ways to guess in sequence prediction. Each way has its good points. Some use Markov models. These guess by looking at the last step. They are easy and good at guessing.\n",
    "\n",
    "Markov models: These models guess the next step by looking at the current step only. They are simple and do their job well.\n",
    "\n",
    "Directed graphs: These show how steps relate. They draw a picture of what comes next based on what happened before. This helps see how things are connected.\n",
    "\n",
    "Recurrent neural networks (RNNs): RNNs are good at remembering what happened in a series step by step. They can spot long patterns well, so they make good guesses about the future.\n",
    "Each way to guess has its own good and bad points. Picking the right way depends on what you need to think. In the next part, we will talk more about these ways. We will see how they work in different areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh as bk\n",
    "import json\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>job_ids</th>\n",
       "      <th>actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[305, 299, 300, 290, 282, 274, 264, 261]</td>\n",
       "      <td>['view', 'view', 'view', 'view', 'view', 'view...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[84, 257, 252, 250]</td>\n",
       "      <td>['view', 'view', 'view', 'view']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[241, 237, 221, 309, 310, 306, 301]</td>\n",
       "      <td>['view', 'view', 'apply', 'apply', 'apply', 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[303, 297, 296, 298, 294, 295, 292, 293]</td>\n",
       "      <td>['apply', 'apply', 'apply', 'apply', 'apply', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[171, 291, 289, 166, 288, 155]</td>\n",
       "      <td>['apply', 'apply', 'apply', 'apply', 'apply', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                                   job_ids  \\\n",
       "0           0  [305, 299, 300, 290, 282, 274, 264, 261]   \n",
       "1           1                       [84, 257, 252, 250]   \n",
       "2           2       [241, 237, 221, 309, 310, 306, 301]   \n",
       "3           3  [303, 297, 296, 298, 294, 295, 292, 293]   \n",
       "4           4            [171, 291, 289, 166, 288, 155]   \n",
       "\n",
       "                                             actions  \n",
       "0  ['view', 'view', 'view', 'view', 'view', 'view...  \n",
       "1                   ['view', 'view', 'view', 'view']  \n",
       "2  ['view', 'view', 'apply', 'apply', 'apply', 'a...  \n",
       "3  ['apply', 'apply', 'apply', 'apply', 'apply', ...  \n",
       "4  ['apply', 'apply', 'apply', 'apply', 'apply', ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>job_id</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>303</td>\n",
       "      <td>apply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>171</td>\n",
       "      <td>apply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>286</td>\n",
       "      <td>apply</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  job_id action\n",
       "0           0      84   view\n",
       "1           1     241   view\n",
       "2           2     303  apply\n",
       "3           3     171  apply\n",
       "4           4     286  apply"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\HRFlow - Recommandation d'emploi basée sur le comportement\\x_train_Meacfjr.csv\")\n",
    "y_train = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\HRFlow - Recommandation d'emploi basée sur le comportement\\y_train_SwJNMSu.csv\")\n",
    "x_test = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\HRFlow - Recommandation d'emploi basée sur le comportement\\x_test_jCBBNP2.csv\")\n",
    "display(x_train.head())\n",
    "display(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_to_list(df, column):\n",
    "    if df[column].dtype == 'object':\n",
    "        df[column] = df[column].apply(lambda x: literal_eval(x) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "# Appliquer aux colonnes job_ids et actions\n",
    "X_train = convert_string_to_list(x_train, 'job_ids')\n",
    "X_train = convert_string_to_list(x_train, 'actions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter des features sur les séquences\n",
    "X_train['session_length'] = X_train['job_ids'].apply(len)\n",
    "X_train['unique_jobs_ratio'] = X_train['job_ids'].apply(lambda x: len(set(x))/len(x) if len(x) > 0 else 0)\n",
    "X_train['apply_ratio'] = X_train['actions'].apply(lambda x: x.count('apply')/len(x) if len(x) > 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>job_ids</th>\n",
       "      <th>actions</th>\n",
       "      <th>session_length</th>\n",
       "      <th>unique_jobs_ratio</th>\n",
       "      <th>apply_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[305, 299, 300, 290, 282, 274, 264, 261]</td>\n",
       "      <td>[view, view, view, view, view, view, view, view]</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[84, 257, 252, 250]</td>\n",
       "      <td>[view, view, view, view]</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[241, 237, 221, 309, 310, 306, 301]</td>\n",
       "      <td>[view, view, apply, apply, apply, apply, apply]</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[303, 297, 296, 298, 294, 295, 292, 293]</td>\n",
       "      <td>[apply, apply, apply, apply, apply, apply, app...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[171, 291, 289, 166, 288, 155]</td>\n",
       "      <td>[apply, apply, apply, apply, apply, apply]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15877</th>\n",
       "      <td>15877</td>\n",
       "      <td>[26581, 27314, 27305, 27327, 27138, 27153]</td>\n",
       "      <td>[apply, apply, apply, apply, apply, apply]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15878</th>\n",
       "      <td>15878</td>\n",
       "      <td>[27220, 27219, 27194]</td>\n",
       "      <td>[view, view, view]</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15879</th>\n",
       "      <td>15879</td>\n",
       "      <td>[27211, 27210, 27209]</td>\n",
       "      <td>[view, view, view]</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15880</th>\n",
       "      <td>15880</td>\n",
       "      <td>[27233, 27220, 27219, 27232, 27231]</td>\n",
       "      <td>[apply, view, view, view, view]</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15881</th>\n",
       "      <td>15881</td>\n",
       "      <td>[27253, 27252, 27251]</td>\n",
       "      <td>[view, view, view]</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15882 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       session_id                                     job_ids  \\\n",
       "0               0    [305, 299, 300, 290, 282, 274, 264, 261]   \n",
       "1               1                         [84, 257, 252, 250]   \n",
       "2               2         [241, 237, 221, 309, 310, 306, 301]   \n",
       "3               3    [303, 297, 296, 298, 294, 295, 292, 293]   \n",
       "4               4              [171, 291, 289, 166, 288, 155]   \n",
       "...           ...                                         ...   \n",
       "15877       15877  [26581, 27314, 27305, 27327, 27138, 27153]   \n",
       "15878       15878                       [27220, 27219, 27194]   \n",
       "15879       15879                       [27211, 27210, 27209]   \n",
       "15880       15880         [27233, 27220, 27219, 27232, 27231]   \n",
       "15881       15881                       [27253, 27252, 27251]   \n",
       "\n",
       "                                                 actions  session_length  \\\n",
       "0       [view, view, view, view, view, view, view, view]               8   \n",
       "1                               [view, view, view, view]               4   \n",
       "2        [view, view, apply, apply, apply, apply, apply]               7   \n",
       "3      [apply, apply, apply, apply, apply, apply, app...               8   \n",
       "4             [apply, apply, apply, apply, apply, apply]               6   \n",
       "...                                                  ...             ...   \n",
       "15877         [apply, apply, apply, apply, apply, apply]               6   \n",
       "15878                                 [view, view, view]               3   \n",
       "15879                                 [view, view, view]               3   \n",
       "15880                    [apply, view, view, view, view]               5   \n",
       "15881                                 [view, view, view]               3   \n",
       "\n",
       "       unique_jobs_ratio  apply_ratio  \n",
       "0                    1.0     0.000000  \n",
       "1                    1.0     0.000000  \n",
       "2                    1.0     0.714286  \n",
       "3                    1.0     1.000000  \n",
       "4                    1.0     1.000000  \n",
       "...                  ...          ...  \n",
       "15877                1.0     1.000000  \n",
       "15878                1.0     0.000000  \n",
       "15879                1.0     0.000000  \n",
       "15880                1.0     0.200000  \n",
       "15881                1.0     0.000000  \n",
       "\n",
       "[15882 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('job_listings.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "emploi = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27359</th>\n",
       "      <th>27360</th>\n",
       "      <th>27361</th>\n",
       "      <th>27362</th>\n",
       "      <th>27363</th>\n",
       "      <th>27364</th>\n",
       "      <th>27365</th>\n",
       "      <th>27366</th>\n",
       "      <th>27367</th>\n",
       "      <th>27368</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TITLE\\nQA Intégration / Data Analyst - SalesF...</td>\n",
       "      <td>TITLE\\nIngénieur Système\\n\\nSUMMARY\\nNous re...</td>\n",
       "      <td>TITLE\\nTesteur QA Automatisation Cypress\\n\\nSU...</td>\n",
       "      <td>TITLE\\nIngénieur support N3 IP - PARIS \\n\\nSU...</td>\n",
       "      <td>TITLE\\nBusiness Analyst MOA FRONT\\n\\nSUMMARY\\n...</td>\n",
       "      <td>TITLE\\nBusiness Analyst SAP S/4\\n\\nSUMMARY\\nNo...</td>\n",
       "      <td>TITLE\\nSalesforce Marketing Cloud Product Owne...</td>\n",
       "      <td>TITLE\\nResponsable Sécurité Opérationnel \\n...</td>\n",
       "      <td>TITLE\\nArchitecte d'entreprise Data BI\\n\\nSUMM...</td>\n",
       "      <td>TITLE\\nIngénieur.e QA web / mobile - (Haute-S...</td>\n",
       "      <td>...</td>\n",
       "      <td>TITLE\\nParis-Administrateur Système DB2 - Z/O...</td>\n",
       "      <td>TITLE\\nIngénieur d’intégration applicative\\n...</td>\n",
       "      <td>TITLE\\nConsultant MS BI Confirmé Build &amp; Run,...</td>\n",
       "      <td>TITLE\\nData modeler / Senior\\n\\nSUMMARY\\nNous ...</td>\n",
       "      <td>TITLE\\nLyon-Développeur Cobol Mainframe-R2030...</td>\n",
       "      <td>TITLE\\nIncident Manager e-commerce\\n\\nSUMMARY\\...</td>\n",
       "      <td>TITLE\\nConsultant Azure Security\\n\\nSUMMARY\\nK...</td>\n",
       "      <td>TITLE\\nChef de projet Supply Chain\\n\\nSUMMARY\\...</td>\n",
       "      <td>TITLE\\nPO Infrastructure\\n\\nSUMMARY\\nUn Produc...</td>\n",
       "      <td>TITLE\\nData Engineer Senior Spark, Scala, Data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21917 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  TITLE\\nQA Intégration / Data Analyst - SalesF...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  TITLE\\nIngénieur Système\\n\\nSUMMARY\\nNous re...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  TITLE\\nTesteur QA Automatisation Cypress\\n\\nSU...   \n",
       "\n",
       "                                                   3  \\\n",
       "0  TITLE\\nIngénieur support N3 IP - PARIS \\n\\nSU...   \n",
       "\n",
       "                                                   4  \\\n",
       "0  TITLE\\nBusiness Analyst MOA FRONT\\n\\nSUMMARY\\n...   \n",
       "\n",
       "                                                   5  \\\n",
       "0  TITLE\\nBusiness Analyst SAP S/4\\n\\nSUMMARY\\nNo...   \n",
       "\n",
       "                                                   6  \\\n",
       "0  TITLE\\nSalesforce Marketing Cloud Product Owne...   \n",
       "\n",
       "                                                   7  \\\n",
       "0  TITLE\\nResponsable Sécurité Opérationnel \\n...   \n",
       "\n",
       "                                                   8  \\\n",
       "0  TITLE\\nArchitecte d'entreprise Data BI\\n\\nSUMM...   \n",
       "\n",
       "                                                   9  ...  \\\n",
       "0  TITLE\\nIngénieur.e QA web / mobile - (Haute-S...  ...   \n",
       "\n",
       "                                               27359  \\\n",
       "0  TITLE\\nParis-Administrateur Système DB2 - Z/O...   \n",
       "\n",
       "                                               27360  \\\n",
       "0  TITLE\\nIngénieur d’intégration applicative\\n...   \n",
       "\n",
       "                                               27361  \\\n",
       "0  TITLE\\nConsultant MS BI Confirmé Build & Run,...   \n",
       "\n",
       "                                               27362  \\\n",
       "0  TITLE\\nData modeler / Senior\\n\\nSUMMARY\\nNous ...   \n",
       "\n",
       "                                               27363  \\\n",
       "0  TITLE\\nLyon-Développeur Cobol Mainframe-R2030...   \n",
       "\n",
       "                                               27364  \\\n",
       "0  TITLE\\nIncident Manager e-commerce\\n\\nSUMMARY\\...   \n",
       "\n",
       "                                               27365  \\\n",
       "0  TITLE\\nConsultant Azure Security\\n\\nSUMMARY\\nK...   \n",
       "\n",
       "                                               27366  \\\n",
       "0  TITLE\\nChef de projet Supply Chain\\n\\nSUMMARY\\...   \n",
       "\n",
       "                                               27367  \\\n",
       "0  TITLE\\nPO Infrastructure\\n\\nSUMMARY\\nUn Produc...   \n",
       "\n",
       "                                               27368  \n",
       "0  TITLE\\nData Engineer Senior Spark, Scala, Data...  \n",
       "\n",
       "[1 rows x 21917 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emploi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emploi = emploi.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column 0 to job_desciption\n",
    "emploi.rename(columns={0: 'job_description'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_sections(df, text_column='description'):\n",
    "    \"\"\"\n",
    "    Extract job sections from text descriptions based on flags like TITLE, SUMMARY, etc.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        DataFrame containing the job descriptions\n",
    "    text_column : str, default='description'\n",
    "        The column containing the job description text\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas DataFrame\n",
    "        Original DataFrame with added columns for job_title and summary\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Create copies of columns to avoid modifying the original DataFrame\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Initialize new columns\n",
    "    df['job_title'] = ''\n",
    "    df['summary'] = ''\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        text = row[text_column]\n",
    "        \n",
    "        # Extract job title (between TITLE and SUMMARY)\n",
    "        title_match = re.search(r'TITLE\\s*\\n(.*?)(?=\\s*\\n\\s*SUMMARY)', text, re.DOTALL)\n",
    "        if title_match:\n",
    "            df.at[idx, 'job_title'] = title_match.group(1).strip()\n",
    "        \n",
    "        # Extract summary (after SUMMARY and before any other section flag)\n",
    "        summary_match = re.search(r'SUMMARY\\s*\\n(.*?)(?=\\s*\\n\\s*SECTION|\\Z)', text, re.DOTALL)\n",
    "        if summary_match:\n",
    "            df.at[idx, 'summary'] = summary_match.group(1).strip()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QA Intégration / Data Analyst - SalesForces S...</td>\n",
       "      <td>Responsabilités :\\nAssurer la qualité des do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ingénieur Système</td>\n",
       "      <td>Nous recherchons un Ingénieur Système pour n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Testeur QA Automatisation Cypress</td>\n",
       "      <td>Vous avez au moins une première expérience s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ingénieur support N3 IP - PARIS</td>\n",
       "      <td>Dans le cadre de cette mission :\\nVous garanti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Analyst MOA FRONT</td>\n",
       "      <td>Nous recherchons un (e) consultant(e) ayant un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  QA Intégration / Data Analyst - SalesForces S...   \n",
       "1                                Ingénieur Système   \n",
       "2                  Testeur QA Automatisation Cypress   \n",
       "3                   Ingénieur support N3 IP - PARIS   \n",
       "4                         Business Analyst MOA FRONT   \n",
       "\n",
       "                                             summary  \n",
       "0  Responsabilités :\\nAssurer la qualité des do...  \n",
       "1  Nous recherchons un Ingénieur Système pour n...  \n",
       "2  Vous avez au moins une première expérience s...  \n",
       "3  Dans le cadre de cette mission :\\nVous garanti...  \n",
       "4  Nous recherchons un (e) consultant(e) ayant un...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "processed_emploi = extract_job_sections(emploi, text_column='job_description')\n",
    "\n",
    "# Display the first few rows to check the results\n",
    "processed_emploi[['job_title', 'summary']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_emploi.drop(columns=[\"job_description\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "processed_emploi.index = processed_emploi.index.astype(int)\n",
    "processed_emploi.index.name = 'job_id'\n",
    "\n",
    "# Create more features from the job text data\n",
    "def extract_additional_features(df):\n",
    "    \"\"\"Extract additional features from job descriptions\"\"\"\n",
    "    # Initialize new columns\n",
    "    df['has_salary_info'] = df['summary'].str.contains('salary|compensation|pay', case=False, regex=True)\n",
    "    df['has_remote_option'] = df['summary'].str.contains('remote|work from home|telecommute', case=False, regex=True)\n",
    "    df['experience_level'] = df['summary'].apply(lambda x: \n",
    "        'senior' if re.search(r'senior|experienced|[5-9]\\+?\\s*years', str(x), re.I) else\n",
    "        'mid' if re.search(r'mid|intermediate|[2-4]\\+?\\s*years', str(x), re.I) else\n",
    "        'junior' if re.search(r'junior|entry|graduate|[0-1]\\+?\\s*years', str(x), re.I) else\n",
    "        'unknown')\n",
    "    \n",
    "    # Extract potential job categories using keyword matching\n",
    "    categories = ['engineering', 'marketing', 'sales', 'finance', 'hr', 'customer service', \n",
    "                 'data science', 'design', 'product', 'operations']\n",
    "    \n",
    "    for category in categories:\n",
    "        df[f'is_{category.replace(\" \", \"_\")}'] = df['job_title'].str.contains(\n",
    "            category, case=False, regex=True) | df['summary'].str.contains(category, case=False, regex=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "processed_emploi = extract_additional_features(processed_emploi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectors for job titles and summaries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# For job titles\n",
    "title_vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "title_vectors = title_vectorizer.fit_transform(processed_emploi['job_title'].fillna(''))\n",
    "\n",
    "# For job summaries\n",
    "summary_vectorizer = TfidfVectorizer(max_features=200, stop_words='english')\n",
    "summary_vectors = summary_vectorizer.fit_transform(processed_emploi['summary'].fillna(''))\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "title_features = pd.DataFrame(\n",
    "    title_vectors.toarray(), \n",
    "    index=processed_emploi.index,\n",
    "    columns=[f'title_term_{i}' for i in range(title_vectors.shape[1])]\n",
    ")\n",
    "\n",
    "summary_features = pd.DataFrame(\n",
    "    summary_vectors.toarray(), \n",
    "    index=processed_emploi.index,\n",
    "    columns=[f'summary_term_{i}' for i in range(summary_vectors.shape[1])]\n",
    ")\n",
    "\n",
    "# Merge with the main job dataframe\n",
    "job_features = pd.concat([processed_emploi, title_features, summary_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>summary</th>\n",
       "      <th>has_salary_info</th>\n",
       "      <th>has_remote_option</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>is_engineering</th>\n",
       "      <th>is_marketing</th>\n",
       "      <th>is_sales</th>\n",
       "      <th>is_finance</th>\n",
       "      <th>is_hr</th>\n",
       "      <th>is_customer_service</th>\n",
       "      <th>is_data_science</th>\n",
       "      <th>is_design</th>\n",
       "      <th>is_product</th>\n",
       "      <th>is_operations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QA Intégration / Data Analyst - SalesForces S...</td>\n",
       "      <td>Responsabilités :\\nAssurer la qualité des do...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ingénieur Système</td>\n",
       "      <td>Nous recherchons un Ingénieur Système pour n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>mid</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Testeur QA Automatisation Cypress</td>\n",
       "      <td>Vous avez au moins une première expérience s...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ingénieur support N3 IP - PARIS</td>\n",
       "      <td>Dans le cadre de cette mission :\\nVous garanti...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Analyst MOA FRONT</td>\n",
       "      <td>Nous recherchons un (e) consultant(e) ayant un...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27364</th>\n",
       "      <td>Incident Manager e-commerce</td>\n",
       "      <td>En charge de la gestion des différents incide...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27365</th>\n",
       "      <td>Consultant Azure Security</td>\n",
       "      <td>KatchMe est un cabinet de placement de consult...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27366</th>\n",
       "      <td>Chef de projet Supply Chain</td>\n",
       "      <td>Beager recherche pour l’un de ses clients, act...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27367</th>\n",
       "      <td>PO Infrastructure</td>\n",
       "      <td>Un Product Owner Infrastructure confirmé (min...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27368</th>\n",
       "      <td>Data Engineer Senior Spark, Scala, Databricks;...</td>\n",
       "      <td>Expérience significative Spark /Scala_x000D_ ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21917 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                job_title  \\\n",
       "job_id                                                      \n",
       "0       QA Intégration / Data Analyst - SalesForces S...   \n",
       "1                                     Ingénieur Système   \n",
       "2                       Testeur QA Automatisation Cypress   \n",
       "3                        Ingénieur support N3 IP - PARIS   \n",
       "4                              Business Analyst MOA FRONT   \n",
       "...                                                   ...   \n",
       "27364                         Incident Manager e-commerce   \n",
       "27365                           Consultant Azure Security   \n",
       "27366                         Chef de projet Supply Chain   \n",
       "27367                                   PO Infrastructure   \n",
       "27368   Data Engineer Senior Spark, Scala, Databricks;...   \n",
       "\n",
       "                                                  summary  has_salary_info  \\\n",
       "job_id                                                                       \n",
       "0       Responsabilités :\\nAssurer la qualité des do...            False   \n",
       "1       Nous recherchons un Ingénieur Système pour n...            False   \n",
       "2       Vous avez au moins une première expérience s...            False   \n",
       "3       Dans le cadre de cette mission :\\nVous garanti...            False   \n",
       "4       Nous recherchons un (e) consultant(e) ayant un...            False   \n",
       "...                                                   ...              ...   \n",
       "27364   En charge de la gestion des différents incide...            False   \n",
       "27365   KatchMe est un cabinet de placement de consult...            False   \n",
       "27366   Beager recherche pour l’un de ses clients, act...            False   \n",
       "27367   Un Product Owner Infrastructure confirmé (min...            False   \n",
       "27368   Expérience significative Spark /Scala_x000D_ ...            False   \n",
       "\n",
       "        has_remote_option experience_level  is_engineering  is_marketing  \\\n",
       "job_id                                                                     \n",
       "0                   False          unknown           False         False   \n",
       "1                   False              mid           False         False   \n",
       "2                   False          unknown           False         False   \n",
       "3                   False          unknown           False         False   \n",
       "4                   False          unknown           False         False   \n",
       "...                   ...              ...             ...           ...   \n",
       "27364               False          unknown           False         False   \n",
       "27365               False          unknown           False         False   \n",
       "27366               False          unknown           False         False   \n",
       "27367               False          unknown           False         False   \n",
       "27368               False          unknown           False         False   \n",
       "\n",
       "        is_sales  is_finance  is_hr  is_customer_service  is_data_science  \\\n",
       "job_id                                                                      \n",
       "0           True       False  False                False            False   \n",
       "1          False       False  False                False            False   \n",
       "2          False       False  False                False            False   \n",
       "3          False       False  False                False            False   \n",
       "4          False       False  False                False            False   \n",
       "...          ...         ...    ...                  ...              ...   \n",
       "27364       True       False  False                False            False   \n",
       "27365      False       False  False                False            False   \n",
       "27366      False       False  False                False            False   \n",
       "27367      False       False  False                False            False   \n",
       "27368      False       False  False                False            False   \n",
       "\n",
       "        is_design  is_product  is_operations  \n",
       "job_id                                        \n",
       "0           False       False          False  \n",
       "1           False       False          False  \n",
       "2           False       False          False  \n",
       "3           False       False          False  \n",
       "4           False       False          False  \n",
       "...           ...         ...            ...  \n",
       "27364       False        True          False  \n",
       "27365       False       False          False  \n",
       "27366       False        True          False  \n",
       "27367       False        True          False  \n",
       "27368       False       False          False  \n",
       "\n",
       "[21917 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_emploi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>job_ids</th>\n",
       "      <th>actions</th>\n",
       "      <th>session_length</th>\n",
       "      <th>unique_jobs_ratio</th>\n",
       "      <th>apply_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[305, 299, 300, 290, 282, 274, 264, 261]</td>\n",
       "      <td>[view, view, view, view, view, view, view, view]</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[84, 257, 252, 250]</td>\n",
       "      <td>[view, view, view, view]</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[241, 237, 221, 309, 310, 306, 301]</td>\n",
       "      <td>[view, view, apply, apply, apply, apply, apply]</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[303, 297, 296, 298, 294, 295, 292, 293]</td>\n",
       "      <td>[apply, apply, apply, apply, apply, apply, app...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[171, 291, 289, 166, 288, 155]</td>\n",
       "      <td>[apply, apply, apply, apply, apply, apply]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15877</th>\n",
       "      <td>15877</td>\n",
       "      <td>[26581, 27314, 27305, 27327, 27138, 27153]</td>\n",
       "      <td>[apply, apply, apply, apply, apply, apply]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15878</th>\n",
       "      <td>15878</td>\n",
       "      <td>[27220, 27219, 27194]</td>\n",
       "      <td>[view, view, view]</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15879</th>\n",
       "      <td>15879</td>\n",
       "      <td>[27211, 27210, 27209]</td>\n",
       "      <td>[view, view, view]</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15880</th>\n",
       "      <td>15880</td>\n",
       "      <td>[27233, 27220, 27219, 27232, 27231]</td>\n",
       "      <td>[apply, view, view, view, view]</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15881</th>\n",
       "      <td>15881</td>\n",
       "      <td>[27253, 27252, 27251]</td>\n",
       "      <td>[view, view, view]</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15882 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       session_id                                     job_ids  \\\n",
       "0               0    [305, 299, 300, 290, 282, 274, 264, 261]   \n",
       "1               1                         [84, 257, 252, 250]   \n",
       "2               2         [241, 237, 221, 309, 310, 306, 301]   \n",
       "3               3    [303, 297, 296, 298, 294, 295, 292, 293]   \n",
       "4               4              [171, 291, 289, 166, 288, 155]   \n",
       "...           ...                                         ...   \n",
       "15877       15877  [26581, 27314, 27305, 27327, 27138, 27153]   \n",
       "15878       15878                       [27220, 27219, 27194]   \n",
       "15879       15879                       [27211, 27210, 27209]   \n",
       "15880       15880         [27233, 27220, 27219, 27232, 27231]   \n",
       "15881       15881                       [27253, 27252, 27251]   \n",
       "\n",
       "                                                 actions  session_length  \\\n",
       "0       [view, view, view, view, view, view, view, view]               8   \n",
       "1                               [view, view, view, view]               4   \n",
       "2        [view, view, apply, apply, apply, apply, apply]               7   \n",
       "3      [apply, apply, apply, apply, apply, apply, app...               8   \n",
       "4             [apply, apply, apply, apply, apply, apply]               6   \n",
       "...                                                  ...             ...   \n",
       "15877         [apply, apply, apply, apply, apply, apply]               6   \n",
       "15878                                 [view, view, view]               3   \n",
       "15879                                 [view, view, view]               3   \n",
       "15880                    [apply, view, view, view, view]               5   \n",
       "15881                                 [view, view, view]               3   \n",
       "\n",
       "       unique_jobs_ratio  apply_ratio  \n",
       "0                    1.0     0.000000  \n",
       "1                    1.0     0.000000  \n",
       "2                    1.0     0.714286  \n",
       "3                    1.0     1.000000  \n",
       "4                    1.0     1.000000  \n",
       "...                  ...          ...  \n",
       "15877                1.0     1.000000  \n",
       "15878                1.0     0.000000  \n",
       "15879                1.0     0.000000  \n",
       "15880                1.0     0.200000  \n",
       "15881                1.0     0.000000  \n",
       "\n",
       "[15882 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features based on session behavior\n",
    "def create_session_features(X_train, y_train):\n",
    "    \"\"\"Create features based on session behavior\"\"\"\n",
    "    # Merge with target data to analyze patterns\n",
    "    session_data = pd.merge(X_train, y_train, on='session_id', how='left')\n",
    "    \n",
    "    # Calculate session-level statistics\n",
    "    session_stats = session_data.groupby('session_id').agg({\n",
    "        'session_length': 'first',\n",
    "        'unique_jobs_ratio': 'first',\n",
    "        'apply_ratio': 'first',\n",
    "        'action': lambda x: 'apply' if 'apply' in x.values else 'view'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate transition probabilities between jobs\n",
    "    transitions = {}\n",
    "    \n",
    "    for _, row in X_train.iterrows():\n",
    "        job_sequence = row['job_ids']\n",
    "        \n",
    "        for i in range(len(job_sequence) - 1):\n",
    "            current_job = job_sequence[i]\n",
    "            next_job = job_sequence[i + 1]\n",
    "            \n",
    "            if current_job not in transitions:\n",
    "                transitions[current_job] = {}\n",
    "            \n",
    "            if next_job not in transitions[current_job]:\n",
    "                transitions[current_job][next_job] = 0\n",
    "                \n",
    "            transitions[current_job][next_job] += 1\n",
    "    \n",
    "    # Normalize transition counts to probabilities\n",
    "    for job_id in transitions:\n",
    "        total = sum(transitions[job_id].values())\n",
    "        for next_job in transitions[job_id]:\n",
    "            transitions[job_id][next_job] /= total\n",
    "    \n",
    "    return session_stats, transitions\n",
    "\n",
    "session_stats, transitions = create_session_features(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>job_ids</th>\n",
       "      <th>actions</th>\n",
       "      <th>session_length</th>\n",
       "      <th>unique_jobs_ratio</th>\n",
       "      <th>apply_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[305, 299, 300, 290, 282, 274, 264, 261]</td>\n",
       "      <td>[view, view, view, view, view, view, view, view]</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[84, 257, 252, 250]</td>\n",
       "      <td>[view, view, view, view]</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[241, 237, 221, 309, 310, 306, 301]</td>\n",
       "      <td>[view, view, apply, apply, apply, apply, apply]</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[303, 297, 296, 298, 294, 295, 292, 293]</td>\n",
       "      <td>[apply, apply, apply, apply, apply, apply, app...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[171, 291, 289, 166, 288, 155]</td>\n",
       "      <td>[apply, apply, apply, apply, apply, apply]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15877</th>\n",
       "      <td>15877</td>\n",
       "      <td>[26581, 27314, 27305, 27327, 27138, 27153]</td>\n",
       "      <td>[apply, apply, apply, apply, apply, apply]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15878</th>\n",
       "      <td>15878</td>\n",
       "      <td>[27220, 27219, 27194]</td>\n",
       "      <td>[view, view, view]</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15879</th>\n",
       "      <td>15879</td>\n",
       "      <td>[27211, 27210, 27209]</td>\n",
       "      <td>[view, view, view]</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15880</th>\n",
       "      <td>15880</td>\n",
       "      <td>[27233, 27220, 27219, 27232, 27231]</td>\n",
       "      <td>[apply, view, view, view, view]</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15881</th>\n",
       "      <td>15881</td>\n",
       "      <td>[27253, 27252, 27251]</td>\n",
       "      <td>[view, view, view]</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15882 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       session_id                                     job_ids  \\\n",
       "0               0    [305, 299, 300, 290, 282, 274, 264, 261]   \n",
       "1               1                         [84, 257, 252, 250]   \n",
       "2               2         [241, 237, 221, 309, 310, 306, 301]   \n",
       "3               3    [303, 297, 296, 298, 294, 295, 292, 293]   \n",
       "4               4              [171, 291, 289, 166, 288, 155]   \n",
       "...           ...                                         ...   \n",
       "15877       15877  [26581, 27314, 27305, 27327, 27138, 27153]   \n",
       "15878       15878                       [27220, 27219, 27194]   \n",
       "15879       15879                       [27211, 27210, 27209]   \n",
       "15880       15880         [27233, 27220, 27219, 27232, 27231]   \n",
       "15881       15881                       [27253, 27252, 27251]   \n",
       "\n",
       "                                                 actions  session_length  \\\n",
       "0       [view, view, view, view, view, view, view, view]               8   \n",
       "1                               [view, view, view, view]               4   \n",
       "2        [view, view, apply, apply, apply, apply, apply]               7   \n",
       "3      [apply, apply, apply, apply, apply, apply, app...               8   \n",
       "4             [apply, apply, apply, apply, apply, apply]               6   \n",
       "...                                                  ...             ...   \n",
       "15877         [apply, apply, apply, apply, apply, apply]               6   \n",
       "15878                                 [view, view, view]               3   \n",
       "15879                                 [view, view, view]               3   \n",
       "15880                    [apply, view, view, view, view]               5   \n",
       "15881                                 [view, view, view]               3   \n",
       "\n",
       "       unique_jobs_ratio  apply_ratio  \n",
       "0                    1.0     0.000000  \n",
       "1                    1.0     0.000000  \n",
       "2                    1.0     0.714286  \n",
       "3                    1.0     1.000000  \n",
       "4                    1.0     1.000000  \n",
       "...                  ...          ...  \n",
       "15877                1.0     1.000000  \n",
       "15878                1.0     0.000000  \n",
       "15879                1.0     0.000000  \n",
       "15880                1.0     0.200000  \n",
       "15881                1.0     0.000000  \n",
       "\n",
       "[15882 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a co-occurrence matrix for job IDs\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Count co-occurrences within sequences\n",
    "co_occurrence = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for sequence in X_train['job_ids']:\n",
    "    for i, job1 in enumerate(sequence):\n",
    "        for j, job2 in enumerate(sequence):\n",
    "            if i != j:\n",
    "                # Weight by proximity (closer jobs have higher weight)\n",
    "                weight = 1.0 / (abs(i - j) + 1)\n",
    "                co_occurrence[job1][job2] += weight\n",
    "\n",
    "# Get all unique job IDs\n",
    "all_job_ids = list(set(job_id for seq in X_train['job_ids'] for job_id in seq))\n",
    "\n",
    "# Create embedding matrix (50 dimensions)\n",
    "embedding_size = 50\n",
    "np.random.seed(42)\n",
    "random_embeddings = {job_id: np.random.randn(embedding_size) for job_id in all_job_ids}\n",
    "\n",
    "# Refine embeddings based on co-occurrence (simple approach)\n",
    "job_embeddings = {}\n",
    "for job_id in all_job_ids:\n",
    "    if job_id in co_occurrence:\n",
    "        # Get co-occurring jobs\n",
    "        co_jobs = co_occurrence[job_id]\n",
    "        if co_jobs:\n",
    "            # Create weighted average of random embeddings\n",
    "            weighted_sum = np.zeros(embedding_size)\n",
    "            total_weight = 0\n",
    "            \n",
    "            for co_job, weight in co_jobs.items():\n",
    "                if co_job in random_embeddings:\n",
    "                    weighted_sum += weight * random_embeddings[co_job]\n",
    "                    total_weight += weight\n",
    "            \n",
    "            if total_weight > 0:\n",
    "                job_embeddings[job_id] = weighted_sum / total_weight\n",
    "            else:\n",
    "                job_embeddings[job_id] = random_embeddings[job_id]\n",
    "        else:\n",
    "            job_embeddings[job_id] = random_embeddings[job_id]\n",
    "    else:\n",
    "        job_embeddings[job_id] = random_embeddings[job_id]\n",
    "\n",
    "# Function to create session vector remains the same\n",
    "def create_session_vector(job_ids, job_embeddings, embedding_size=50):\n",
    "    \"\"\"Create a session vector by averaging job embeddings with recency weighting\"\"\"\n",
    "    if not job_ids:\n",
    "        return np.zeros(embedding_size)\n",
    "    \n",
    "    # Apply recency weighting - more recent jobs have higher weight\n",
    "    weights = np.linspace(0.5, 1.0, len(job_ids))\n",
    "    \n",
    "    vectors = []\n",
    "    for i, job_id in enumerate(job_ids):\n",
    "        if job_id in job_embeddings:\n",
    "            weighted_vector = job_embeddings[job_id] * weights[i]\n",
    "            vectors.append(weighted_vector)\n",
    "    \n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    return np.zeros(embedding_size)\n",
    "\n",
    "# Apply to sessions using the same create_session_vector function\n",
    "X_train['session_vector'] = X_train['job_ids'].apply(\n",
    "    lambda x: create_session_vector(x, job_embeddings, embedding_size)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovJobRecommender:\n",
    "    def __init__(self, transitions, job_embeddings, embedding_size=50):\n",
    "        self.transitions = transitions\n",
    "        self.job_embeddings = job_embeddings\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Create a similarity matrix between all jobs based on embeddings\n",
    "        self.similarity_matrix = {}\n",
    "        job_ids = list(job_embeddings.keys())\n",
    "        \n",
    "        for i, job1 in enumerate(job_ids):\n",
    "            self.similarity_matrix[job1] = {}\n",
    "            for job2 in job_ids:\n",
    "                if job1 != job2:\n",
    "                    # Cosine similarity between job embeddings\n",
    "                    similarity = np.dot(job_embeddings[job1], job_embeddings[job2]) / (\n",
    "                        np.linalg.norm(job_embeddings[job1]) * np.linalg.norm(job_embeddings[job2])\n",
    "                    )\n",
    "                    self.similarity_matrix[job1][job2] = similarity\n",
    "    \n",
    "    def recommend_next_jobs(self, job_sequence, top_n=10):\n",
    "        \"\"\"Recommend next jobs based on Markov transitions and embedding similarity\"\"\"\n",
    "        if not job_sequence:\n",
    "            return []\n",
    "        \n",
    "        # Get the last job in the sequence\n",
    "        last_job = job_sequence[-1]\n",
    "        \n",
    "        # Get transition probabilities from the last job\n",
    "        transition_probs = self.transitions.get(last_job, {})\n",
    "        \n",
    "        # Get similar jobs based on embeddings\n",
    "        similar_jobs = self.similarity_matrix.get(last_job, {})\n",
    "        \n",
    "        # Combine transition probabilities and similarities\n",
    "        scores = {}\n",
    "        \n",
    "        # Add scores from transitions (with higher weight)\n",
    "        for job_id, prob in transition_probs.items():\n",
    "            if job_id not in job_sequence:  # Avoid recommending already seen jobs\n",
    "                scores[job_id] = 0.7 * prob\n",
    "        \n",
    "        # Add scores from similarities (with lower weight)\n",
    "        for job_id, sim in similar_jobs.items():\n",
    "            if job_id not in job_sequence:  # Avoid recommending already seen jobs\n",
    "                scores[job_id] = scores.get(job_id, 0) + 0.3 * sim\n",
    "        \n",
    "        # Sort by score and get top_n\n",
    "        recommended_jobs = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        return [job_id for job_id, _ in recommended_jobs]\n",
    "\n",
    "# Initialize the recommender\n",
    "markov_recommender = MarkovJobRecommender(transitions, job_embeddings, embedding_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Prepare data for LSTM\n",
    "def prepare_sequence_data(X_train, y_train, job_embeddings, max_seq_length=20):\n",
    "    \"\"\"Prepare sequence data for LSTM model\"\"\"\n",
    "    # Get all unique job IDs\n",
    "    all_job_ids = list(set(job_id for seq in X_train['job_ids'] for job_id in seq))\n",
    "    all_job_ids.sort()  # Ensure consistent ordering\n",
    "    \n",
    "    # Create job ID to index mapping\n",
    "    job_to_idx = {job_id: idx + 1 for idx, job_id in enumerate(all_job_ids)}  # +1 for padding (0)\n",
    "    idx_to_job = {idx + 1: job_id for idx, job_id in enumerate(all_job_ids)}\n",
    "    \n",
    "    # Convert job sequences to index sequences\n",
    "    X_sequences = [\n",
    "        [job_to_idx[job_id] for job_id in seq[-max_seq_length:]]  # Use only the last max_seq_length jobs\n",
    "        for seq in X_train['job_ids']\n",
    "    ]\n",
    "    \n",
    "    # Pad sequences\n",
    "    X_padded = pad_sequences(X_sequences, maxlen=max_seq_length, padding='pre')\n",
    "    \n",
    "    # Convert target job IDs to indices\n",
    "    y_indices = [job_to_idx.get(job_id, 0) for job_id in y_train['target_job_id']]\n",
    "    \n",
    "    # Convert target actions to binary (1 for 'apply', 0 for 'view')\n",
    "    y_actions = (y_train['action'] == 'apply').astype(int).values\n",
    "    \n",
    "    return X_padded, y_indices, y_actions, job_to_idx, idx_to_job, len(all_job_ids) + 1\n",
    "\n",
    "# Prepare data\n",
    "X_padded, y_indices, y_actions, job_to_idx, idx_to_job, num_jobs = prepare_sequence_data(\n",
    "    X_train, y_train, job_embeddings\n",
    ")\n",
    "\n",
    "# Create embedding matrix from pre-trained job embeddings\n",
    "embedding_matrix = np.zeros((num_jobs, embedding_size))\n",
    "for job_id, idx in job_to_idx.items():\n",
    "    if job_id in job_embeddings:\n",
    "        embedding_matrix[idx] = job_embeddings[job_id]\n",
    "\n",
    "# Build LSTM model for job prediction\n",
    "job_model = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=num_jobs,\n",
    "        output_dim=embedding_size,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_seq_length,\n",
    "        trainable=False\n",
    "    ),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_jobs, activation='softmax')\n",
    "])\n",
    "\n",
    "job_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Build model for action prediction\n",
    "action_model = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=num_jobs,\n",
    "        output_dim=embedding_size,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_seq_length,\n",
    "        trainable=False\n",
    "    ),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "action_model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train models\n",
    "job_history = job_model.fit(\n",
    "    X_padded, y_indices,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "action_history = action_model.fit(\n",
    "    X_padded, y_actions,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel, BertTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to prepare job descriptions for BERT\n",
    "def prepare_job_descriptions(job_ids, processed_emploi):\n",
    "    \"\"\"Get job descriptions for a sequence of job IDs\"\"\"\n",
    "    descriptions = []\n",
    "    for job_id in job_ids:\n",
    "        if job_id in processed_emploi.index:\n",
    "            title = processed_emploi.loc[job_id, 'job_title']\n",
    "            summary = processed_emploi.loc[job_id, 'summary']\n",
    "            descriptions.append(f\"{title} {summary}\")\n",
    "        else:\n",
    "            descriptions.append(\"\")\n",
    "    return descriptions\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to prepare BERT inputs\n",
    "def prepare_bert_input(job_ids, processed_emploi, max_length=512):\n",
    "    \"\"\"Prepare BERT inputs for a job sequence\"\"\"\n",
    "    # Get descriptions for the last 5 jobs (to fit within BERT's context window)\n",
    "    if len(job_ids) > 5:\n",
    "        job_ids = job_ids[-5:]\n",
    "    \n",
    "    descriptions = prepare_job_descriptions(job_ids, processed_emploi)\n",
    "    combined_text = \" [SEP] \".join(descriptions)\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        combined_text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    \n",
    "    return inputs\n",
    "def build_bert_model(num_jobs):\n",
    "    \"\"\"Build a BERT-based model for job and action prediction\"\"\"\n",
    "    # BERT base model\n",
    "    bert = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # Inputs\n",
    "    input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    # BERT outputs\n",
    "    bert_outputs = bert(input_ids, attention_mask=attention_mask)\n",
    "    sequence_output = bert_outputs[0]\n",
    "    pooled_output = bert_outputs[1]\n",
    "    \n",
    "    # Common layers\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(pooled_output)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Job prediction branch\n",
    "    job_output = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    job_output = tf.keras.layers.Dropout(0.2)(job_output)\n",
    "    job_output = tf.keras.layers.Dense(num_jobs, activation='softmax', name='job_prediction')(job_output)\n",
    "    \n",
    "    # Action prediction branch\n",
    "    action_output = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    action_output = tf.keras.layers.Dropout(0.2)(action_output)\n",
    "    action_output = tf.keras.layers.Dense(1, activation='sigmoid', name='action_prediction')(action_output)\n",
    "    \n",
    "    # Create model\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_ids, attention_mask],\n",
    "        outputs=[job_output, action_output]\n",
    "    )\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "        loss={\n",
    "            'job_prediction': 'sparse_categorical_crossentropy',\n",
    "            'action_prediction': 'binary_crossentropy'\n",
    "        },\n",
    "        metrics={\n",
    "            'job_prediction': 'accuracy',\n",
    "            'action_prediction': 'accuracy'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create BERT model\n",
    "bert_model = build_bert_model(num_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobRecommendationEnsemble:\n",
    "    def __init__(self, markov_recommender, lstm_model, bert_model, job_to_idx, idx_to_job, processed_emploi):\n",
    "        self.markov_recommender = markov_recommender\n",
    "        self.lstm_model = lstm_model\n",
    "        self.bert_model = bert_model\n",
    "        self.job_to_idx = job_to_idx\n",
    "        self.idx_to_job = idx_to_job\n",
    "        self.processed_emploi = processed_emploi\n",
    "        self.max_seq_length = 20  # Same as used in LSTM\n",
    "    \n",
    "    def predict_next_jobs(self, job_sequence, top_n=10):\n",
    "        \"\"\"Predict next jobs using ensemble of models\"\"\"\n",
    "        # 1. Markov predictions\n",
    "        markov_predictions = self.markov_recommender.recommend_next_jobs(job_sequence, top_n=top_n)\n",
    "        \n",
    "        # 2. LSTM predictions\n",
    "        # Convert job sequence to indices and pad\n",
    "        lstm_input = [self.job_to_idx.get(job_id, 0) for job_id in job_sequence[-self.max_seq_length:]]\n",
    "        lstm_input = pad_sequences([lstm_input], maxlen=self.max_seq_length, padding='pre')\n",
    "        \n",
    "        # Get LSTM predictions\n",
    "        lstm_probs = self.lstm_model.predict(lstm_input)[0]\n",
    "        lstm_top_indices = np.argsort(lstm_probs)[-top_n*2:][::-1]  # Get more candidates\n",
    "        lstm_predictions = [self.idx_to_job.get(idx, 0) for idx in lstm_top_indices \n",
    "                           if idx in self.idx_to_job and self.idx_to_job[idx] not in job_sequence][:top_n]\n",
    "        \n",
    "        # 3. BERT predictions\n",
    "        # Prepare BERT input\n",
    "        bert_inputs = prepare_bert_input(job_sequence, self.processed_emploi)\n",
    "        \n",
    "        # Get BERT predictions\n",
    "        bert_outputs = self.bert_model.predict({\n",
    "            'input_ids': bert_inputs['input_ids'],\n",
    "            'attention_mask': bert_inputs['attention_mask']\n",
    "        })\n",
    "        \n",
    "        bert_probs = bert_outputs[0][0]  # Job prediction probabilities\n",
    "        bert_top_indices = np.argsort(bert_probs)[-top_n*2:][::-1]  # Get more candidates\n",
    "        bert_predictions = [self.idx_to_job.get(idx, 0) for idx in bert_top_indices \n",
    "                           if idx in self.idx_to_job and self.idx_to_job[idx] not in job_sequence][:top_n]\n",
    "        \n",
    "        # 4. Ensemble predictions with weighted voting\n",
    "        # Assign weights to each model\n",
    "        weights = {\n",
    "            'markov': 0.3,\n",
    "            'lstm': 0.3,\n",
    "            'bert': 0.4\n",
    "        }\n",
    "        \n",
    "        # Combine predictions with weights\n",
    "        job_scores = {}\n",
    "        \n",
    "        # Add Markov scores\n",
    "        for i, job_id in enumerate(markov_predictions):\n",
    "            score = weights['markov'] * (1.0 - i/len(markov_predictions))\n",
    "            job_scores[job_id] = job_scores.get(job_id, 0) + score\n",
    "        \n",
    "        # Add LSTM scores\n",
    "        for i, job_id in enumerate(lstm_predictions):\n",
    "            score = weights['lstm'] * (1.0 - i/len(lstm_predictions))\n",
    "            job_scores[job_id] = job_scores.get(job_id, 0) + score\n",
    "        \n",
    "        # Add BERT scores\n",
    "        for i, job_id in enumerate(bert_predictions):\n",
    "            score = weights['bert'] * (1.0 - i/len(bert_predictions))\n",
    "            job_scores[job_id] = job_scores.get(job_id, 0) + score\n",
    "        \n",
    "        # Sort by score and get top_n\n",
    "        final_predictions = sorted(job_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        final_job_ids = [job_id for job_id, _ in final_predictions]\n",
    "        \n",
    "        # If we don't have enough predictions, fill with Markov and LSTM predictions\n",
    "        if len(final_job_ids) < top_n:\n",
    "            remaining = top_n - len(final_job_ids)\n",
    "            additional_jobs = []\n",
    "            \n",
    "            for job_id in markov_predictions + lstm_predictions:\n",
    "                if job_id not in final_job_ids and job_id not in additional_jobs:\n",
    "                    additional_jobs.append(job_id)\n",
    "                    if len(additional_jobs) >= remaining:\n",
    "                        break\n",
    "            \n",
    "            final_job_ids.extend(additional_jobs)\n",
    "        \n",
    "        return final_job_ids[:top_n]\n",
    "    \n",
    "    def predict_action(self, job_sequence):\n",
    "        \"\"\"Predict next action (apply or view)\"\"\"\n",
    "        # Prepare BERT input\n",
    "        bert_inputs = prepare_bert_input(job_sequence, self.processed_emploi)\n",
    "        \n",
    "        # Get BERT action prediction\n",
    "        bert_outputs = self.bert_model.predict({\n",
    "            'input_ids': bert_inputs['input_ids'],\n",
    "            'attention_mask': bert_inputs['attention_mask']\n",
    "        })\n",
    "        \n",
    "        bert_action_prob = bert_outputs[1][0][0]  # Action prediction probability\n",
    "        \n",
    "        # Convert LSTM input\n",
    "        lstm_input = [self.job_to_idx.get(job_id, 0) for job_id in job_sequence[-self.max_seq_length:]]\n",
    "        lstm_input = pad_sequences([lstm_input], maxlen=self.max_seq_length, padding='pre')\n",
    "        \n",
    "        # Get LSTM action prediction\n",
    "        lstm_action_prob = action_model.predict(lstm_input)[0][0]\n",
    "        \n",
    "        # Weighted average of predictions\n",
    "        final_action_prob = 0.6 * bert_action_prob + 0.4 * lstm_action_prob\n",
    "        \n",
    "        # Return 'apply' if probability > 0.5, else 'view'\n",
    "        return 'apply' if final_action_prob > 0.5 else 'view'\n",
    "\n",
    "# Initialize ensemble\n",
    "ensemble = JobRecommendationEnsemble(\n",
    "    markov_recommender,\n",
    "    job_model,\n",
    "    bert_model,\n",
    "    job_to_idx,\n",
    "    idx_to_job,\n",
    "    processed_emploi\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mrr(true_item, predicted_items):\n",
    "    \"\"\"Calculate Mean Reciprocal Rank\"\"\"\n",
    "    if true_item in predicted_items:\n",
    "        rank = predicted_items.index(true_item) + 1\n",
    "        return 1.0 / rank\n",
    "    return 0.0\n",
    "\n",
    "def evaluate_model(X_test, y_test, ensemble):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    mrr_scores = []\n",
    "    action_predictions = []\n",
    "    true_actions = []\n",
    "    \n",
    "    for i, (x_row, y_row) in enumerate(zip(X_test.iterrows(), y_test.iterrows())):\n",
    "        _, x_data = x_row\n",
    "        _, y_data = y_row\n",
    "        \n",
    "        job_sequence = x_data['job_ids']\n",
    "        true_job = y_data['target_job_id']\n",
    "        true_action = y_data['action']\n",
    "        \n",
    "        # Get predictions\n",
    "        predicted_jobs = ensemble.predict_next_jobs(job_sequence, top_n=10)\n",
    "        predicted_action = ensemble.predict_action(job_sequence)\n",
    "        \n",
    "        # Calculate MRR\n",
    "        mrr = calculate_mrr(true_job, predicted_jobs)\n",
    "        mrr_scores.append(mrr)\n",
    "        \n",
    "        # Record action predictions\n",
    "        action_predictions.append(1 if predicted_action == 'apply' else 0)\n",
    "        true_actions.append(1 if true_action == 'apply' else 0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_mrr = np.mean(mrr_scores)\n",
    "    action_accuracy = np.mean(np.array(action_predictions) == np.array(true_actions))\n",
    "    \n",
    "    # Calculate final score (70% MRR, 30% action accuracy)\n",
    "    final_score = 0.7 * avg_mrr + 0.3 * action_accuracy\n",
    "    \n",
    "    return {\n",
    "        'MRR': avg_mrr,\n",
    "        'Action Accuracy': action_accuracy,\n",
    "        'Final Score': final_score\n",
    "    }\n",
    "\n",
    "def prepare_submission(X_test, ensemble, output_file='submission.csv'):\n",
    "    \"\"\"Prepare submission file\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, row in X_test.iterrows():\n",
    "        session_id = row['session_id']\n",
    "        job_sequence = row['job_ids']\n",
    "        \n",
    "        # Get predictions\n",
    "        predicted_jobs = ensemble.predict_next_jobs(job_sequence, top_n=10)\n",
    "        predicted_action = ensemble.predict_action(job_sequence)\n",
    "        \n",
    "        # Ensure we have exactly 10 predictions\n",
    "        if len(predicted_jobs) < 10:\n",
    "            # Fill with random jobs not in the sequence\n",
    "            all_jobs = list(processed_emploi.index)\n",
    "            random_jobs = [job for job in all_jobs if job not in job_sequence and job not in predicted_jobs]\n",
    "            np.random.shuffle(random_jobs)\n",
    "            predicted_jobs.extend(random_jobs[:10-len(predicted_jobs)])\n",
    "        \n",
    "        # Limit to 10 predictions\n",
    "        predicted_jobs = predicted_jobs[:10]\n",
    "        \n",
    "        # Add to results\n",
    "        results.append({\n",
    "            'session_id': session_id,\n",
    "            'job_1': predicted_jobs[0] if len(predicted_jobs) > 0 else None,\n",
    "            'job_2': predicted_jobs[1] if len(predicted_jobs) > 1 else None,\n",
    "            'job_3': predicted_jobs[2] if len(predicted_jobs) > 2 else None,\n",
    "            'job_4': predicted_jobs[3] if len(predicted_jobs) > 3 else None,\n",
    "            'job_5': predicted_jobs[4] if len(predicted_jobs) > 4 else None,\n",
    "            'job_6': predicted_jobs[5] if len(predicted_jobs) > 5 else None,\n",
    "            'job_7': predicted_jobs[6] if len(predicted_jobs) > 6 else None,\n",
    "            'job_8': predicted_jobs[7] if len(predicted_jobs) > 7 else None,\n",
    "            'job_9': predicted_jobs[8] if len(predicted_jobs) > 8 else None,\n",
    "            'job_10': predicted_jobs[9] if len(predicted_jobs) > 9 else None,\n",
    "            'applies_for': 1 if predicted_action == 'apply' else 0\n",
    "        })\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save to CSV\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    print(f\"Submission saved to {output_file}\")\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "# Evaluate on validation set\n",
    "X_test_processed = convert_string_to_list(x_test, 'job_ids')\n",
    "X_test_processed = convert_string_to_list(X_test_processed, 'actions')\n",
    "\n",
    "# Add the same features as training data\n",
    "X_test_processed['session_length'] = X_test_processed['job_ids'].apply(len)\n",
    "X_test_processed['unique_jobs_ratio'] = X_test_processed['job_ids'].apply(lambda x: len(set(x))/len(x) if len(x) > 0 else 0)\n",
    "X_test_processed['apply_ratio'] = X_test_processed['actions'].apply(lambda x: x.count('apply')/len(x) if len(x) > 0 else 0)\n",
    "\n",
    "# Create submission\n",
    "submission = prepare_submission(X_test_processed, ensemble, 'ensemble_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize job embeddings using t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Get embeddings for visualization\n",
    "job_ids = list(job_embeddings.keys())\n",
    "embedding_vectors = np.array([job_embeddings[job_id] for job_id in job_ids])\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "job_tsne = tsne.fit_transform(embedding_vectors)\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "tsne_df = pd.DataFrame({\n",
    "    'job_id': job_ids,\n",
    "    'x': job_tsne[:, 0],\n",
    "    'y': job_tsne[:, 1]\n",
    "})\n",
    "\n",
    "# Add job titles\n",
    "tsne_df['job_title'] = tsne_df['job_id'].apply(\n",
    "    lambda x: processed_emploi.loc[x, 'job_title'] if x in processed_emploi.index else ''\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.scatterplot(data=tsne_df, x='x', y='y', alpha=0.7)\n",
    "\n",
    "# Add labels for some points\n",
    "for i, row in tsne_df.sample(20).iterrows():\n",
    "    plt.text(row['x'], row['y'], row['job_title'][:20], fontsize=8)\n",
    "\n",
    "plt.title('t-SNE Visualization of Job Embeddings')\n",
    "plt.xlabel('t-SNE dimension 1')\n",
    "plt.ylabel('t-SNE dimension 2')\n",
    "plt.show()\n",
    "\n",
    "# Visualize session lengths\n",
    "plt.figure(figsize\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
